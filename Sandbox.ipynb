{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sandbox.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOuryqwAgxbNQnXbs2J11Bx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/D-Sokol/denotarikon/blob/main/Sandbox.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-l-0OeQjXhO",
        "outputId": "e562d968-218d-459b-9432-2f865ec6b555"
      },
      "source": [
        "!pip install transformers==4.1.1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers==4.1.1 in /usr/local/lib/python3.6/dist-packages (4.1.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==4.1.1) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==4.1.1) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==4.1.1) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==4.1.1) (20.8)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==4.1.1) (0.8)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers==4.1.1) (0.9.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==4.1.1) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==4.1.1) (1.19.4)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==4.1.1) (0.0.43)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.1.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.1.1) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.1.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.1.1) (2020.12.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==4.1.1) (2.4.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==4.1.1) (1.0.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==4.1.1) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==4.1.1) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieG-Qb3Mh0Hd"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import string\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVOB60vVjPju"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', add_prefix_space=True)\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2').train(False).to(device)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iN-fd1hgrY6j"
      },
      "source": [
        "all_tokens = [tokenizer.decode(i) for i in range(tokenizer.vocab_size)]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OB0gB2PtVtn"
      },
      "source": [
        "mask = torch.zeros(tokenizer.vocab_size, len(string.ascii_lowercase), dtype=bool)\n",
        "for token, mask_row in zip(all_tokens, mask):\n",
        "    if token.startswith(' '):\n",
        "        if len(token) == 1 or token[1].lower() not in string.ascii_lowercase:\n",
        "            continue\n",
        "        mask_row[string.ascii_lowercase.index(token[1].lower())] = True\n",
        "    elif token and token[0] not in string.ascii_uppercase:\n",
        "        mask_row[:] = True"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1GOGGfmjhq6",
        "outputId": "109d5ff8-6c00-445d-f80a-94465658ad67"
      },
      "source": [
        "start_text = \"The best possible example to demonstrate power of the project is\"\n",
        "start_tokens = tokenizer.encode(start_text)\n",
        "start_tokens"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[383, 1266, 1744, 1672, 284, 10176, 1176, 286, 262, 1628, 318]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvgBMqjHTE7K"
      },
      "source": [
        "# Parameter for nucleus sampling\n",
        "p_threshold = 0.95\n",
        "# Desired number of tokens in the result.\n",
        "n_tokens = 111"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlRDYccBmg9y"
      },
      "source": [
        "tokens = start_tokens[:]\n",
        "with torch.no_grad():\n",
        "    result = model(torch.tensor(tokens, device=device)[None], past_key_values=None)\n",
        "    next_logits, past = result['logits'][0, -1, :], result['past_key_values']\n",
        "    for i in range(len(tokens), n_tokens):\n",
        "        # TODO: consider other letters, not only T\n",
        "        next_logits[~mask[:, 19]] = -np.inf\n",
        "        next_probas = torch.softmax(next_logits, dim=-1).cpu()\n",
        "\n",
        "        sorted_p, sorted_ix = torch.sort(next_probas, descending=True)\n",
        "        cumulative_p = torch.cumsum(sorted_p, dim=-1)\n",
        "\n",
        "        # Number of possible choices for next token, calculated as minimal n\n",
        "        #  such that sum of probabilities of the first n tokens exceeds p_threshold\n",
        "        n_tokens_next = np.argmax(cumulative_p.numpy() > p_threshold) + 1\n",
        "\n",
        "        sorted_p = sorted_p[:n_tokens_next]\n",
        "        sorted_p /= cumulative_p[n_tokens_next-1]\n",
        "        ix_ix = np.random.choice(n_tokens_next, p=sorted_p.numpy())\n",
        "        next_ix = sorted_ix[ix_ix]\n",
        "        tokens.append(next_ix.item())\n",
        "\n",
        "        result = model(next_ix[None], past_key_values=past)\n",
        "        next_logits, past = result['logits'][0, :], result['past_key_values']"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAyDvGAzPC_P",
        "outputId": "c6f3aec4-f66a-49b8-ed41-ba6dd9a44bc5"
      },
      "source": [
        "print(tokenizer.decode(tokens))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " The best possible example to demonstrate power of the project is to talk to the top ten teachers. They tell their teachers:\n",
            "\n",
            "\"talk to, tell the top ten teachers.\" That's the top ten teachers. They've talked to the top ten teachers, they've talked to them. They're talking to them. They're telling them they're the top ten teachers.\n",
            "\n",
            "you're the top ten teacher, tell them, the top ten teachers.\n",
            "\n",
            "top ten, tell them, the top ten teachers.\n",
            "\n",
            "top ten, tell\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}